{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67634241-d734-47f9-be99-9c2f6b9160f8",
   "metadata": {},
   "source": [
    "# **Guide to Maximum Bipartite Matching in ViMMS (Updated 21/04/2024)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af1abc3-fb5f-41a1-a77b-b58110d227de",
   "metadata": {},
   "source": [
    "This notebook is a guide to fragmentation strategies in ViMMS based on the use of maximum matching algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fdc7d4e-11b6-4a82-a7bf-368f7d28c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "user_vimms = os.path.join( # Put your path to your install of ViMMS here!\n",
    "    \"C:\\\\\",\n",
    "    \"Users\",\n",
    "    \"mcbrider5002\",\n",
    "    \"Desktop\",\n",
    "    \"Workspace\",\n",
    "    \"phd\",\n",
    "    \"peak_picking\",\n",
    "    \"vimms\"\n",
    ")\n",
    "\n",
    "sys.path.append(user_vimms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15e7da5-448f-4bf1-9fe5-1264ba879974",
   "metadata": {},
   "source": [
    "### **What is \"Maximum Bipartite Matching\"?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcdf12f-f591-488a-ad8d-f4605828ef07",
   "metadata": {},
   "source": [
    "Computing scientists study many types of allocation problems in order to develop algorithms which compute an optimal assignment of some resource, and perform this computation with an efficient use of computing power. One such class of problem is a \"matching\" problem where you have a list of parties, or resources, and a list of preference or compatibility criteria, and you must make pairs of them such that no individual is double-allocated. A maximum matching is a list of these pairs such that no list with more pairs exists for a given input problem. \n",
    "\n",
    "This can be represented pictorially like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891a36b-8b10-47b3-8607-4d7fa8f9c335",
   "metadata": {},
   "source": [
    "<img src=\"images/bipartite_matching.svg\" width=360 height=360 style=\"margin:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a003272-41c2-4536-9014-89156959379e",
   "metadata": {},
   "source": [
    "This formalism is a computational graph; the circles or \"vertices\" represent an individual instance of our abstract \"resource\"; and the lines joining them, or \"edges\", represent compatibility between the two, meaning we can form a pair between them. This graph has a special structure where there are two groups of vertices and all edges join a vertex in one group to another: this structure is a bipartite graph. A maximum bipartite matching is just a matching computed on a graph with this structure: the extra restrictions mean a prospective algorithm has to consider less possible cases and thus we can deploy a more efficient algorithm to this problem compared to the general matching problem.\n",
    "\n",
    "The lines marked in red highlight a particular candidate matching. Each edge chosen for the matching must, by definition, not touch a vertex touched by any other edge included in the matching: we can see this requirement is satisfied. Additionally, all scans from one side of the graph are assigned so this matching is \"full\" or \"one-sided perfect\". It follows trivially that it must also be a maximum matching: all vertices from one side of the graph have been assigned, and the other group of vertices has only edges that lead to these already-assigned vertices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaeeb83-a743-44a5-a645-9b5f7f65e56d",
   "metadata": {},
   "source": [
    "### **Why Matching?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd2cbd-ecd5-49b4-80f9-11a4d33da9fa",
   "metadata": {},
   "source": [
    "So how does this relate to fragmentation strategies? The relationships between MS2 scans and target chromatographic peaks can be modelled as such a bipartite graph. Each MS2 scan and each chromatographic peak becomes a vertex on opposite sides of the bipartite graph. Then, an edge exists between a given pair of vertices if one is an MS2 scan and the other is a chromatographic peak for which that MS2 scan would be able to target to acquire a fragmentation spectrum. Having defined this construct we can efficiently resolve the assignments of MS2s to peaks such that the maximum number of peaks possible are targeted.\n",
    "\n",
    "It would, of course, be easy to perform the above example by hand. But in LC-MS/MS data you might have thousands or tens of thousands of MS2 scans and peaks, and millions of edges joining the two. Even for a computer program with a well-structured problem definition like this, this task is not trivial and may be time-consuming. By leveraging efficient algorithms designed for the maximum bipartite matching problem, like the Hopcroft-Karp algorithm, we can use someone else's implementation not written for this specific problem to solve hard instances like these. We need only construct the appropriate graph structure first.\n",
    "\n",
    "To construct this graph in ViMMS you need three pieces of input data: a _scan schedule_, a _target list_ and some _representative data_. The _scan schedule_ specifies what order to run MS1 and MS2 scans in, and their expected durations: the MS2 scans here will form one set of vertices. The _target list_ is a list of bounding boxes in (RT, m/z) space, one per peak you would like to target: these form the other set of vertices. The _representative data_ is some previous observation of the data (preferably one MS1-only fullscan .mzML per sample you would like to run) from which we can see intensity readings for each peak-box at a given point in time. This then allows us to construct edges: an MS2-peak pair has an edge if the MS2 overlaps with the peak-box in time _and_ the MS2 has a preceding MS1 with an intensity reading above some minimum threshold inside the peak-box.\n",
    "\n",
    "Having constructed our graph, we can call our standard algorithm on it to get a maximum matching. That maximum matching can be utilised in several ways for fragmentation strategies. For example, we can directly run a \"pre-scheduled\" method by running the exact schedule we gave the matching algorithm and targeting MS2 scans at the peak they were paired with in the matching. Or, we can create inclusion windows for a DDA method by taking the scan time of any MS2 scan included in the matching and drawing a fixed-size window around it. An overview of the whole process can be seen below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27a979-8e21-4376-b703-b60536ed22cb",
   "metadata": {},
   "source": [
    "<img src=\"images/matching_workflow.svg\" width=820 height=820 style=\"margin:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00489e-9f29-4bd3-9fde-4f22487ee2f5",
   "metadata": {},
   "source": [
    "In our work we have also extended this basic bipartite matching concept to multiple samples (by creating one graph per run and combining them), intensity acquisition optimisation (by marking each edge with the intensity value of that acquisition, and solving the maximum weighted bipartite matching to find the matching with the greatest sum of these values) and to full assignments (by using heuristic rules to assign any leftover scans not included in the matching). Using these techniques is also covered in this notebook.\n",
    "\n",
    "Do note that there are other kinds of matching problem: for example, the Stable Marriage problem, rather than just indicating a binary compatibility between two vertices, has each vertex come with a preference list stating its order of preference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc7df7-76fc-48ae-aef8-923c27e57f9f",
   "metadata": {},
   "source": [
    "## **Quick-Start**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133e1b1-ae1b-4ff3-9a4e-2c1fd8234a89",
   "metadata": {},
   "source": [
    "The easiest way to use a `Matching`-based fragmentation strategy is the `make_matching` convenience method. Let's run an `Experiment` with TopN Exclusion, a pre-scheduled matching and TopNEx with DDA inclusion windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aba1ffc-533b-450d-a3f8-11fefb22ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\mcbrider5002\\anaconda3\\lib\\site-packages\\psims\\mzmlb\\writer.py:33: UserWarning:hdf5plugin is missing! Only the slower GZIP compression scheme will be available! Please install hdf5plugin to be able to use Blosc.\n"
     ]
    }
   ],
   "source": [
    "from vimms.Common import POSITIVE\n",
    "from vimms.Roi import RoiBuilderParams\n",
    "from vimms.PeakPicking import XCMSScriptParams\n",
    "from vimms.Matching import MatchingScan, Matching\n",
    "from vimms.BoxManager import BoxManager\n",
    "from vimms.Experiment import ExperimentCase, Experiment\n",
    "from vimms.Controller.misc import TaskFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4983abe-d5a7-4764-bd44-4a8e8f8d8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some stuff for the experiment in general and the DDA controllers\n",
    "# See the Guide to ViMMS for more information on basic usage\n",
    "\n",
    "out_dir = os.path.join(\"results\", \"matching\")\n",
    "xcms_r_script = os.path.join(user_vimms, \"vimms\", \"scripts\", \"xcms_script.R\")\n",
    "\n",
    "num_workers = 8\n",
    "ionisation_mode = POSITIVE\n",
    "min_rt, max_rt = 0, 1440\n",
    "isolation_width = 1\n",
    "intensity_threshold = 5000\n",
    "scan_duration_dict = {1: 0.59, 2: 0.19}\n",
    "\n",
    "topN_params = {\n",
    "    \"ionisation_mode\" : ionisation_mode,\n",
    "    \"N\" : 20,\n",
    "    \"isolation_width\" : isolation_width,\n",
    "    \"min_ms1_intensity\" : intensity_threshold,\n",
    "    \"mz_tol\" : 10,\n",
    "    \"rt_tol\" : 60\n",
    "}\n",
    "\n",
    "topNEXt_params = {\n",
    "    **topN_params,\n",
    "    \"min_roi_length_for_fragmentation\" : 0,\n",
    "    \"roi_params\" : RoiBuilderParams(\n",
    "        min_roi_intensity=0,\n",
    "        min_roi_length=3,\n",
    "    )\n",
    "}\n",
    "\n",
    "pp_params = XCMSScriptParams(\n",
    "    xcms_r_script = xcms_r_script,\n",
    ")\n",
    "\n",
    "beer_fullscans = [os.path.join(\"fixtures\", f\"fullscan_beer{i}_0.mzML\") for i in range(1, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123cb20c-7179-4737-9833-6a58a907b99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16942 aligned boxes contained in file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 12:26:42.961 | DEBUG    | vimms.Chemicals:_extract_rois:834 - Extracted 291410 good ROIs from fixtures\\fullscan_beer1_0.mzML\n",
      "2024-04-24 12:30:12.327 | DEBUG    | vimms.Chemicals:_extract_rois:834 - Extracted 318956 good ROIs from fixtures\\fullscan_beer2_0.mzML\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching_size: 12422\n",
      "chem_count: 16942\n",
      "scan_count: 26240\n",
      "edge_count: 4348654\n",
      "chems_above_threshold: 15681\n",
      "start_scan: 2024-04-24 12:23:45.274803\n",
      "end_scan: 2024-04-24 12:31:29.597922\n",
      "start_chem: 2024-04-24 12:31:30.706579\n",
      "end_chem: 2024-04-24 12:31:30.880215\n",
      "start_matching: 2024-04-24 12:31:30.888256\n",
      "end_matching: 2024-04-24 12:34:50.307590\n",
      "start_assign: 2024-04-24 12:34:50.307590\n",
      "end_assign: 2024-04-24 12:36:45.275396\n"
     ]
    }
   ],
   "source": [
    "# Make a Matching object, which can be used directly for a pre-scheduled controller\n",
    "\n",
    "# Representative data, i.e. the run structure we would like to have...\n",
    "fullscan_paths = beer_fullscans * 2\n",
    "\n",
    "# What times we expect to run scans at, and at what MS level\n",
    "times_list = [list(MatchingScan.topN_times(N, max_rt, scan_duration_dict)) for N in [20] * len(fullscan_paths)]\n",
    "\n",
    "# Use a peak-picker on the representative data to define our target list\n",
    "aligned_file = pp_params.pick_aligned_peaks(\n",
    "    input_files = fullscan_paths,\n",
    "    output_dir = out_dir,\n",
    "    output_name = f\"{len(fullscan_paths)}_beer_peak_picked.csv\",\n",
    "    force = False\n",
    ")\n",
    "\n",
    "shared_matching_params = {\n",
    "    \"fullscan_paths\" : fullscan_paths, # Representative data per each LC-MS/MS run to do\n",
    "    \"times_list\" : times_list, # Times and levels for scans to be run\n",
    "    \"aligned_reader\" : XCMSScriptParams, # How to read the target list format\n",
    "    \"aligned_file\" : aligned_file, # Peak-picked file\n",
    "    \"ionisation_mode\" : ionisation_mode,\n",
    "    \"intensity_threshold\" : intensity_threshold # Only create edges above this threshold\n",
    "}\n",
    "\n",
    "matching = Matching.make_matching( # Create a Matching object with desired properties\n",
    "    **shared_matching_params,\n",
    "    weighted=Matching.TWOSTEP, # Optimise coverage then acquisition intensities\n",
    "    full_assignment_strategy=Matching.RECURSIVE_ASSIGNMENT # Assign leftover scans by repeatedly running matchings on them\n",
    ")\n",
    "\n",
    "matching.log.summarise() # Show some interesting information about the Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da6c449-fcd3-490f-9036-6ed20714ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the matching object into inclusion windows of fixed size and slot it into a TopNEXt BoxManager\n",
    "\n",
    "inclusion_boxes = matching.make_inclusion_boxes(rt_width=10, mz_width=10)\n",
    "grid_base = BoxManager(inclusion_boxes=inclusion_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4621d115-d221-4056-937f-9b7307c84fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Chemicals...\n",
      "\n",
      "Running Experiment of 3 cases...\n"
     ]
    }
   ],
   "source": [
    "# Run the Experiment\n",
    "\n",
    "tfilter = TaskFilter(scan_duration_dict[1], scan_duration_dict[2]) # Add TaskFilter for dynamic rescheduling\n",
    "\n",
    "\n",
    "exp = Experiment()\n",
    "exp.add_cases([\n",
    "    ExperimentCase(\"topN_exclusion\", fullscan_paths, topN_params),\n",
    "    ExperimentCase(\"matching\", fullscan_paths,  {\"isolation_width\": isolation_width, \"task_filter\": tfilter}, shareable_base=matching, name=\"two_step_matching_with_recursive_assignment\"),\n",
    "    ExperimentCase(\"topNEX\", fullscan_paths, topNEXt_params, shareable_base=grid_base, name=\"topNEX_inclusion\"),\n",
    "])\n",
    "\n",
    "exp.run_experiment(\n",
    "    out_dir=out_dir,\n",
    "    min_rt=min_rt,\n",
    "    max_rt=max_rt,\n",
    "    ionisation_mode=ionisation_mode,\n",
    "    scan_duration_dict=scan_duration_dict,\n",
    "    overwrite_keyfile=False,\n",
    "    point_noise_threshold=0,\n",
    "    chem_noise_threshold=0,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caac506a-16a7-4cd2-ad80-0deb67e34158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16942 aligned boxes contained in file\n",
      "16942 aligned boxes contained in file\n",
      "16942 aligned boxes contained in file\n",
      "\n",
      "two_step_matching_with_recursive_assignment\n",
      "Number of chems above min intensity: 15681\n",
      "Number of fragmentations: [6560, 6560, 6560, 6560]\n",
      "Cumulative coverage: [4703, 9237, 11426, 13603]\n",
      "Cumulative coverage proportion: [0.2999170971239079, 0.5890568203558446, 0.7286525094062879, 0.867482941138958]\n",
      "Cumulative intensity proportion: [0.21935683419503332, 0.44876641379529536, 0.5638165494658173, 0.6881781131630043]\n",
      "Cumulative intensity proportion of covered spectra: [0.7313915621969631, 0.7618389233218607, 0.7737797402567373, 0.7933044911055701]\n",
      "Times covered: {0: 3339, 1: 8325, 2: 4384, 3: 565, 4: 329}\n",
      "Times fragmented: {0: 2737, 1: 6005, 2: 3520, 3: 1692, 4: 740, 5: 493, 6: 401, 7: 320, 8: 207, 9: 124, 10: 85, 11: 64, 12: 60, 13: 44, 14: 65, 15: 56, 16: 43, 17: 30, 18: 29, 19: 26, 20: 18, 21: 25, 22: 17, 23: 5, 24: 12, 25: 7, 26: 3, 27: 4, 28: 4, 29: 6, 30: 8, 31: 3, 32: 13, 33: 3, 34: 4, 35: 6, 37: 2, 38: 2, 39: 8, 40: 3, 41: 4, 42: 4, 43: 1, 44: 4, 45: 1, 46: 1, 50: 1, 53: 1, 54: 1, 56: 1, 72: 1, 77: 1, 78: 1, 85: 1, 89: 7, 95: 1, 107: 1, 110: 10, 117: 1, 130: 1, 150: 1, 196: 1, 199: 1, 207: 1}\n",
      "\n",
      "topNEX_inclusion\n",
      "Number of chems above min intensity: 16094\n",
      "Number of fragmentations: [6390, 4601, 3412, 3688]\n",
      "Cumulative coverage: [4192, 8179, 10317, 12281]\n",
      "Cumulative coverage proportion: [0.2604697402758792, 0.5082018143407481, 0.6410463526780167, 0.7630794084752082]\n",
      "Cumulative intensity proportion: [0.16773979600371886, 0.35055460551207906, 0.4525646277573317, 0.562213140241853]\n",
      "Cumulative intensity proportion of covered spectra: [0.6439895698673309, 0.6897940849873335, 0.7059780090265093, 0.7367688526221302]\n",
      "Times covered: {0: 4661, 1: 8276, 2: 3368, 3: 511, 4: 126}\n",
      "Times fragmented: {0: 3569, 1: 6539, 2: 3655, 3: 1695, 4: 695, 5: 314, 6: 144, 7: 102, 8: 29, 9: 43, 10: 34, 11: 13, 12: 16, 13: 6, 14: 2, 15: 8, 16: 5, 17: 4, 19: 1, 20: 1, 22: 2, 25: 4, 26: 1, 27: 1, 28: 8, 32: 8, 33: 1, 36: 1, 40: 5, 41: 7, 42: 3, 43: 1, 46: 1, 47: 1, 65: 2, 66: 4, 73: 1, 74: 10, 76: 1, 96: 1, 104: 1, 115: 1, 117: 1, 119: 1}\n",
      "\n",
      "topN_exclusion\n",
      "Number of chems above min intensity: 16124\n",
      "Number of fragmentations: [6406, 4533, 3049, 3039]\n",
      "Cumulative coverage: [3725, 7123, 8986, 10378]\n",
      "Cumulative coverage proportion: [0.23102207888861326, 0.4417638303150583, 0.5573058794343835, 0.6436368146861821]\n",
      "Cumulative intensity proportion: [0.13878934415864458, 0.2935206437211433, 0.3872676450807511, 0.46485539065120685]\n",
      "Cumulative intensity proportion of covered spectra: [0.6007622510641571, 0.6644288725761217, 0.6948924448344125, 0.7222324454480689]\n",
      "Times covered: {0: 6564, 1: 7278, 2: 2602, 3: 406, 4: 92}\n",
      "Times fragmented: {0: 5314, 1: 5797, 2: 3161, 3: 1428, 4: 586, 5: 276, 6: 95, 7: 70, 8: 40, 9: 21, 10: 27, 11: 7, 12: 11, 13: 4, 14: 10, 15: 1, 17: 8, 18: 6, 22: 5, 25: 1, 29: 6, 33: 7, 34: 3, 35: 5, 36: 4, 37: 1, 38: 9, 39: 1, 40: 1, 46: 9, 51: 8, 57: 8, 60: 1, 63: 1, 64: 1, 71: 1, 72: 1, 74: 1, 85: 1, 87: 4, 88: 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Experiment and show some results\n",
    "\n",
    "exp.evaluate(\n",
    "    pp_params=pp_params,\n",
    "    num_workers=num_workers,\n",
    "    isolation_widths=isolation_width,\n",
    "    aligned_names=f\"{len(fullscan_paths)}_beer_peak_picked.csv\",\n",
    "    force_peak_picking = False,\n",
    "    check_files = \"exact\"\n",
    ")\n",
    "\n",
    "exp.summarise(\n",
    "    num_workers=num_workers,\n",
    "    min_intensities=intensity_threshold,\n",
    "    rank_key = \"cumulative_intensity_proportion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5bbc1-d390-4994-835c-d2a5091fb85e",
   "metadata": {},
   "source": [
    "# **Matching In-Depth**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e560d-1574-4704-8cbe-9c223db45719",
   "metadata": {},
   "source": [
    "The `make_matching` function automates a lot of the steps but it is possible to manually initialise the `Matching` instead. This involves creation of both sets of vertices as `MatchingScans` and `MatchingChems` and then initialisation of the matching itself through `multi_schedule2graph`.\n",
    "\n",
    "First, though, let's import some things, define our input data and define a logging object so we can pass it to constructors (we'll see how to use it later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d96220a-f161-4f29-ab44-4895046f6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vimms.Common import POSITIVE\n",
    "from vimms.PeakPicking import XCMSScriptParams\n",
    "from vimms.Matching import MatchingScan, MatchingChem, Matching, MatchingLog\n",
    "\n",
    "out_dir = os.path.join(\"results\", \"matching\")\n",
    "xcms_r_script = os.path.join(user_vimms, \"vimms\", \"scripts\", \"xcms_script.R\")\n",
    "\n",
    "ionisation_mode = POSITIVE\n",
    "min_rt, max_rt = 0, 1440\n",
    "isolation_width = 1\n",
    "intensity_threshold = 5000\n",
    "scan_duration_dict = {1: 0.59, 2: 0.19}\n",
    "\n",
    "beer_fullscans = [os.path.join(\"fixtures\", f\"fullscan_beer{i}_0.mzML\") for i in range(1, 3)]\n",
    "fullscan_paths = beer_fullscans * 2\n",
    "\n",
    "log = MatchingLog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a62a56-8b32-4ae1-83f3-30592f5a0671",
   "metadata": {},
   "source": [
    "#### **MatchingScans**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f5d11-356a-4857-92b3-4f0292fa6f44",
   "metadata": {},
   "source": [
    "A MatchingScan represents what an individual scan is expected to look like in an upcoming scan schedule. An MS1 scan has an RT and a list of (m/z, intensity) pairs which are created by interpolating scans in the representative data. MS2 scans only have the RT and will become vertices in the graph. We need one scan schedule per each LC-MS/MS run we plan to do.\n",
    "\n",
    "We already defined the representative data, so now we just need to define the scan schedule. We can make one straightforwardly with the `topN_times` method, but for the sake of demonstration let's do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "798a6b75-7209-4969-be8f-6aecfffa90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 12:58:37.918 | DEBUG    | vimms.Chemicals:_extract_rois:834 - Extracted 291410 good ROIs from fixtures\\fullscan_beer1_0.mzML\n",
      "2024-04-24 13:02:09.206 | DEBUG    | vimms.Chemicals:_extract_rois:834 - Extracted 318956 good ROIs from fixtures\\fullscan_beer2_0.mzML\n"
     ]
    }
   ],
   "source": [
    "N = 20\n",
    "scan_idx = 1\n",
    "times_list = [(1, 0.0)]\n",
    "last_level, last_time = times_list[-1]\n",
    "\n",
    "while(last_time < max_rt):\n",
    "    new_level = 1 if scan_idx % N == 0 else 2\n",
    "    new_rt = last_time + scan_duration_dict[last_level]\n",
    "    times_list.append((new_level, new_rt))\n",
    "    \n",
    "    last_level, last_time = times_list[-1]\n",
    "    scan_idx += 1\n",
    "\n",
    "times_list = [times_list] * len(fullscan_paths)\n",
    "\n",
    "scans_list = MatchingScan.mzmls2scans(\n",
    "    fullscan_paths,\n",
    "    times_list, \n",
    "    ionisation_mode, \n",
    "    log=log\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3275b1-e4f5-4716-a237-9a685ccbaacd",
   "metadata": {},
   "source": [
    "### **MatchingChems**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eaf321-f83e-4027-aed8-dd23ed2530fc",
   "metadata": {},
   "source": [
    "`MatchingChems` represent the targets for the matching method to aim MS2 scans at. They're specified as a rectangle in (RT, m/z) space, and form the other side of the bipartite graph from the MS2 `MatchingScans`. The target list should specify where each target is expected to be per each run (their absence in a given run is allowed) so that we define an $m\\times{}n$ matrix where the row index gives the specific target and the column index gives the run, or vice-versa. \n",
    "\n",
    "We'll pick peaks, align them, and then read the peak-list back in from the output file, but any method of generating targets suffices given a file listing them and an object which knows how to read the file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f8e2e58-2d61-49a2-a93a-673ecb5ebd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16942 aligned boxes contained in file\n"
     ]
    }
   ],
   "source": [
    "pp_params = XCMSScriptParams(\n",
    "    xcms_r_script = xcms_r_script,\n",
    ")\n",
    "\n",
    "aligned_file = pp_params.pick_aligned_peaks(\n",
    "    input_files = fullscan_paths,\n",
    "    output_dir = out_dir,\n",
    "    output_name = f\"{len(fullscan_paths)}_beer_peak_picked.csv\",\n",
    "    force = False\n",
    ")\n",
    "\n",
    "chems_list = MatchingChem.boxfile2nodes(\n",
    "    XCMSScriptParams, # File reader\n",
    "    aligned_file,\n",
    "    fullscan_paths,\n",
    "    log=log\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390098d-f225-460a-bdba-a84b1dece138",
   "metadata": {},
   "source": [
    "### **Matching**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bee278-6ba1-4cc2-b725-71306e62888d",
   "metadata": {},
   "source": [
    "Now we have both the `MatchingScans` and `MatchingChems` (one list of each per LC-MS/MS run we want to perform) we can construct our bipartite graph and solve a matching. First, edges are constructed. For each run we overlay the `MatchingScans` with the `MatchingChems`. Then for each MS2 `MatchingScan` we create an edge between it and any `MatchingChem` if all of the following conditions are met:\n",
    "\n",
    "    * The MS2 `MatchingScan` intersects the `MatchingChem`'s box on the RT dimension;\n",
    "    * The MS2 `MatchingScan` has a precursor MS1 `MatchingScan` with a point also within the (RT, m/z) bounds of the `MatchingChem`'s box;\n",
    "    * That precursor point is above a minimum intensity threshold.\n",
    "\n",
    "That edge is then labelled with the intensity of the precursor point, to allow optimising acquisition intensity. We now have all the objects we would need to instantiate one bipartite graph per injection, but to plan for the whole acquisition they must be combined first. `MatchingScans` are simply transferred to the new graph as-is (while tracking the index of the run they came from) but `MatchingChems` are combined using the alignment information written into the data file they were read from. All edges continue to persist between a `MatchingScan` and an aligned `MatchingChem` where the edge would join that `MatchingScan` and one of the `MatchingChems` combined into the aligned `MatchingChem` by this process. After this, we pass these objects to NetworkX and let it solve the maximum bipartite matching for us. If we also wish to optimise acquisition intensity, then an auxiliary graph is created using only the `MatchingChems` included in that maximum matching, and a maximum weighted bipartite matching is solved on that graph. (Deleting excess `MatchingChems` is necessary due to an implementation detail of NetworkX.)\n",
    "\n",
    "All of these steps can be performed internally by `multi_schedule2graph`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c627399-3b96-48ef-9e30-3df40c75fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_threshold = 5000\n",
    "\n",
    "basic_matching = Matching.multi_schedule2graph(\n",
    "    scans_list,\n",
    "    chems_list,\n",
    "    intensity_threshold,\n",
    "    edge_limit=None, # If you need this to run faster, you can set this to the maximum number of edges allowed on any vertex, and clip any extras, starting from the lowest intensity\n",
    "    weighted=Matching.TWOSTEP,\n",
    "    full_assignment_strategy=Matching.MATCHING_ONLY,\n",
    "    log=log\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e2422-1be9-47b1-a92a-c913e0c01dc7",
   "metadata": {},
   "source": [
    "It's also possible to use the parameters to control whether the matching is weighted (i.e. whether we optimise acquisition intensity) and how we assign any leftover scans that weren't included in the matching. `weighted` controls the mode for weighted assignment, and `full_assignment_strategy` controls how the leftover scans are made into a full assignment.\n",
    "\n",
    "It's also possible to change the full assignment after the `Matching` object is created via `assign_remaining_scans`. Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f2da003-b621-4502-815a-4f24ad7ce3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "recursive_matching = copy.deepcopy(basic_matching) # We're going to show the difference shortly so we don't want to modify the original object\n",
    "recursive_matching.assign_remaining_scans(Matching.RECURSIVE_ASSIGNMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbd6f5-500a-488e-889f-45d667aadd51",
   "metadata": {},
   "source": [
    "These objects can also be freely turned into inclusion windows as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e405d40d-7712-4602-a212-52d8e5e997e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vimms.BoxManager import BoxManager\n",
    "\n",
    "inclusion_boxes = basic_matching.make_inclusion_boxes(rt_width=10, mz_width=10)\n",
    "grid_base = BoxManager(inclusion_boxes=inclusion_boxes) # Needed to use them with a TopNEXt controller, but you could do something else with them instead..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096688dd-70d1-4830-88eb-a3a6fdd62c75",
   "metadata": {},
   "source": [
    "Note that only items in the matching itself are used for inclusion windows, not the whole assignment. \n",
    "\n",
    "Also, the `Matching` continues to store intermediate steps like the constructed NetworkX graph internally. While this can be useful, sometimes these data can be quite large - by calling the `strip` method you can delete them and free memory space. Do note that this will prevent operations that require these to still be present, like recomputing the full assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d26334-b59a-4252-9eef-e6ada5e941a9",
   "metadata": {},
   "source": [
    "### **MatchingLog**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956af767-2a17-4b3d-9819-a01f536ce3e2",
   "metadata": {},
   "source": [
    "The `MatchingLog` object we've been passing around can give us some useful information about the matching we computed. First let's call `matching_report` to fill out some of the information it tracks, then let's see what it can show us with `summarise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441ff511-7a2c-4859-a172-0c4d6911062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching_size: 12387\n",
      "chem_count: 16942\n",
      "scan_count: 26060\n",
      "edge_count: 4331608\n",
      "chems_above_threshold: 15702\n",
      "start_scan: 2024-04-24 12:55:29.404268\n",
      "end_scan: 2024-04-24 13:03:23.881703\n",
      "start_chem: 2024-04-24 13:03:25.064226\n",
      "end_chem: 2024-04-24 13:03:26.588461\n",
      "start_matching: 2024-04-24 13:03:26.621160\n",
      "end_matching: 2024-04-24 13:06:36.333119\n",
      "start_assign: 2024-04-24 13:06:36.333119\n",
      "end_assign: 2024-04-24 13:06:36.353476\n"
     ]
    }
   ],
   "source": [
    "basic_matching.matching_report()\n",
    "log.summarise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d2746-5a93-4473-b0e5-dff176ea5046",
   "metadata": {},
   "source": [
    "Of course, the recursive matching we deepcopied has its own log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18747796-7781-42f0-a500-28419b806799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching_size: 12387\n",
      "chem_count: 16942\n",
      "scan_count: 26060\n",
      "edge_count: 4331608\n",
      "chems_above_threshold: 15702\n",
      "start_scan: 2024-04-24 12:55:29.404268\n",
      "end_scan: 2024-04-24 13:03:23.881703\n",
      "start_chem: 2024-04-24 13:03:25.064226\n",
      "end_chem: 2024-04-24 13:03:26.588461\n",
      "start_matching: 2024-04-24 13:03:26.621160\n",
      "end_matching: 2024-04-24 13:06:36.333119\n",
      "start_assign: 2024-04-24 13:07:28.364436\n",
      "end_assign: 2024-04-24 13:09:26.878849\n"
     ]
    }
   ],
   "source": [
    "recursive_matching.matching_report()\n",
    "recursive_matching.log.summarise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eabc6f-16a9-4bf9-93a4-ec7aa663b88f",
   "metadata": {},
   "source": [
    "We can also specify which fields we want to get out of summarise - not all are enabled by default. e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08fbf176-d208-408f-855e-73e3f9922ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching_size: 12387\n",
      "recursive_scan_counts: [25976, 13589, 10686, 8655, 7012, 5518, 4369, 3535, 3031, 2733, 2465, 2234, 2012, 1803, 1620, 1445, 1324, 1236, 1150, 1069, 989, 910, 832, 757, 694, 634, 578, 523, 473, 425, 380, 336, 294, 259, 232, 208, 184, 160, 136, 112, 90, 68, 46, 24, 6]\n"
     ]
    }
   ],
   "source": [
    "recursive_matching.log.summarise([\"matching_size\", \"recursive_scan_counts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99492f99-da25-45e4-bf8e-5a842a5dec30",
   "metadata": {},
   "source": [
    "### **MatchingController and TaskFilter**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393a0acf-ca69-4d9d-bb67-31218dc5cd20",
   "metadata": {},
   "source": [
    "The pre-scheduled matching is weak to unexpected changes in its plan, and can even become completely desynchronised. However, the `MatchingController` (like other pre-scheduled controllers in ViMMS) can use a task filtering object to dynamically adjust its schedule (likely in simpler ways than computing the original plan). Experiment therefore also allows passing a `task_filter` to matching controllers.\n",
    "\n",
    "Let's define one using the base `TaskFilter` class and test it in an experiment where scan times are consistently longer than expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1576d09c-7a33-465f-bc70-90d1a953bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vimms.Controller.misc import TaskFilter\n",
    "\n",
    "tfilter = TaskFilter(\n",
    "    scan_duration_dict[1], # NB this is still conditioned on the expected times for scans\n",
    "    scan_duration_dict[2],\n",
    "    skip_margin=0.5, # Default value, how aggressively we skip missed items\n",
    "    add_margin=1.2 # Default value, how aggressively we pad schedule with items to pass time \n",
    ")\n",
    "\n",
    "true_duration_dict = {level: 1.1 * t for level, t in scan_duration_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "590794ff-3bb2-4e6e-aeb5-e197f4794051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DDA stuff again...\n",
    "\n",
    "from vimms.Roi import RoiBuilderParams\n",
    "\n",
    "topN_params = {\n",
    "    \"ionisation_mode\" : ionisation_mode,\n",
    "    \"N\" : 20,\n",
    "    \"isolation_width\" : isolation_width,\n",
    "    \"min_ms1_intensity\" : intensity_threshold,\n",
    "    \"mz_tol\" : 10,\n",
    "    \"rt_tol\" : 60\n",
    "}\n",
    "\n",
    "topNEXt_params = {\n",
    "    **topN_params,\n",
    "    \"min_roi_length_for_fragmentation\" : 0,\n",
    "    \"roi_params\" : RoiBuilderParams(\n",
    "        min_roi_intensity=0,\n",
    "        min_roi_length=3,\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2f65d21-e2e4-438f-b103-80e2a0f15c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Chemicals...\n",
      "\n",
      "Running Experiment of 5 cases...\n"
     ]
    }
   ],
   "source": [
    "# Run the new Experiment\n",
    "\n",
    "from vimms.Experiment import ExperimentCase, Experiment\n",
    "\n",
    "num_workers = 8\n",
    "\n",
    "exp = Experiment()\n",
    "exp.add_cases([\n",
    "    ExperimentCase(\"matching\", fullscan_paths,  {\"isolation_width\": isolation_width}, shareable_base=basic_matching, name=\"two_step_matching\"),\n",
    "    ExperimentCase(\"matching\", fullscan_paths,  {\"isolation_width\": isolation_width, \"task_filter\": tfilter}, shareable_base=basic_matching, name=\"adaptive_two_step_matching\"),\n",
    "    ExperimentCase(\"matching\", fullscan_paths,  {\"isolation_width\": isolation_width}, shareable_base=recursive_matching, name=\"two_step_matching_with_recursive_assignment\"),\n",
    "    ExperimentCase(\"matching\", fullscan_paths,  {\"isolation_width\": isolation_width, \"task_filter\": tfilter}, shareable_base=recursive_matching, name=\"adaptive_two_step_matching_with_recursive_assignment\"),\n",
    "    ExperimentCase(\"topNEX\", fullscan_paths, topNEXt_params, shareable_base=grid_base, name=\"topNEX_inclusion\"),\n",
    "])\n",
    "\n",
    "exp.run_experiment(\n",
    "    out_dir=out_dir,\n",
    "    min_rt=min_rt,\n",
    "    max_rt=max_rt,\n",
    "    ionisation_mode=ionisation_mode,\n",
    "    scan_duration_dict=true_duration_dict,\n",
    "    overwrite_keyfile=False,\n",
    "    point_noise_threshold=0,\n",
    "    chem_noise_threshold=0,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b8bce79-41d3-480d-85ee-2ff6988c4499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16942 aligned boxes contained in file\n",
      "16942 aligned boxes contained in file\n",
      "16942 aligned boxes contained in file\n",
      "16942 aligned boxes contained in file\n",
      "16942 aligned boxes contained in file\n",
      "\n",
      "adaptive_two_step_matching_with_recursive_assignment\n",
      "Number of chems above min intensity: 15717\n",
      "Number of fragmentations: [5825, 5825, 5825, 5825]\n",
      "Cumulative coverage: [3422, 6681, 8836, 11143]\n",
      "Cumulative coverage proportion: [0.2177260291404212, 0.42508112235159384, 0.562193802888592, 0.7089775402430489]\n",
      "Cumulative intensity proportion: [0.1687237338429701, 0.33403116854739234, 0.4371519308412744, 0.5486226887142749]\n",
      "Cumulative intensity proportion of covered spectra: [0.774935980365272, 0.78580569915572, 0.7775822653952366, 0.7738223816317201]\n",
      "Times covered: {0: 5799, 1: 8907, 2: 1871, 3: 193, 4: 172}\n",
      "Times fragmented: {0: 5609, 1: 8637, 2: 789, 3: 357, 4: 246, 5: 382, 6: 298, 7: 250, 8: 114, 9: 25, 10: 19, 11: 16, 12: 29, 13: 26, 14: 38, 15: 20, 16: 6, 17: 2, 18: 1, 19: 3, 20: 8, 21: 6, 22: 5, 23: 3, 24: 2, 26: 5, 27: 3, 28: 6, 29: 3, 30: 6, 31: 2, 32: 2, 33: 1, 35: 1, 36: 1, 37: 1, 38: 6, 39: 5, 40: 4, 41: 2, 42: 2, 44: 1}\n",
      "\n",
      "adaptive_two_step_matching\n",
      "Number of chems above min intensity: 15717\n",
      "Number of fragmentations: [5825, 5825, 5825, 5825]\n",
      "Cumulative coverage: [2571, 5306, 7854, 10807]\n",
      "Cumulative coverage proportion: [0.16358083603741172, 0.3375962333778711, 0.4997136858179042, 0.687599414646561]\n",
      "Cumulative intensity proportion: [0.12683381413699074, 0.2583383376670525, 0.3840748148591899, 0.5307197981035934]\n",
      "Cumulative intensity proportion of covered spectra: [0.7753586374138792, 0.7652287322112823, 0.7685897460073704, 0.771844458850206]\n",
      "Times covered: {0: 6135, 1: 10807}\n",
      "Times fragmented: {0: 5935, 1: 11007}\n",
      "\n",
      "topNEX_inclusion\n",
      "Number of chems above min intensity: 16041\n",
      "Number of fragmentations: [5903, 4321, 3180, 3431]\n",
      "Cumulative coverage: [2858, 5434, 7555, 9516]\n",
      "Cumulative coverage proportion: [0.17816844336388005, 0.33875693535315754, 0.47098061218128545, 0.5932298485131849]\n",
      "Cumulative intensity proportion: [0.12122969488472836, 0.23475531540615321, 0.33286253176225605, 0.429246236155783]\n",
      "Cumulative intensity proportion of covered spectra: [0.6804218109327949, 0.6929904332775311, 0.706743596558352, 0.7235749132172041]\n",
      "Times covered: {0: 7426, 1: 8443, 2: 1064, 3: 9}\n",
      "Times fragmented: {0: 7297, 1: 8470, 2: 1102, 3: 69, 4: 3, 5: 1}\n",
      "\n",
      "two_step_matching_with_recursive_assignment\n",
      "Number of chems above min intensity: 15658\n",
      "Number of fragmentations: [5922, 5922, 5922, 5922]\n",
      "Cumulative coverage: [383, 807, 981, 1258]\n",
      "Cumulative coverage proportion: [0.024460339762421766, 0.05153914931664325, 0.06265167965257376, 0.08034231702644015]\n",
      "Cumulative intensity proportion: [0.01638757117542799, 0.03425745308661671, 0.041338000800466096, 0.05251789207448535]\n",
      "Cumulative intensity proportion of covered spectra: [0.6699649855479152, 0.6646879807066225, 0.6598067446826689, 0.6536765930860824]\n",
      "Times covered: {0: 15684, 1: 908, 2: 305, 3: 10, 4: 35}\n",
      "Times fragmented: {0: 15323, 1: 1036, 2: 209, 3: 83, 4: 43, 5: 37, 6: 30, 7: 22, 8: 11, 9: 12, 10: 13, 11: 9, 12: 4, 13: 8, 14: 4, 15: 11, 16: 8, 17: 3, 18: 5, 19: 8, 20: 2, 21: 3, 22: 2, 23: 7, 24: 5, 25: 3, 26: 2, 27: 3, 28: 3, 29: 1, 31: 1, 32: 6, 33: 4, 34: 1, 36: 3, 38: 1, 42: 1, 43: 2, 44: 6, 45: 4, 46: 1, 52: 1, 55: 1}\n",
      "\n",
      "two_step_matching\n",
      "Number of chems above min intensity: 15658\n",
      "Number of fragmentations: [5922, 5922, 5922, 5922]\n",
      "Cumulative coverage: [226, 547, 755, 1067]\n",
      "Cumulative coverage proportion: [0.014433516413335037, 0.03493421892962064, 0.04821816323923873, 0.06814407970366586]\n",
      "Cumulative intensity proportion: [0.008862940577335773, 0.02134231750114589, 0.02978396463507941, 0.042449846885361034]\n",
      "Cumulative intensity proportion of covered spectra: [0.6140527591147059, 0.610928715599529, 0.6176918122596998, 0.6229425515754293]\n",
      "Times covered: {0: 15875, 1: 1021, 2: 44, 3: 2}\n",
      "Times fragmented: {0: 15537, 1: 1317, 2: 83, 3: 5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Experiment and show some results\n",
    "\n",
    "exp.evaluate(\n",
    "    pp_params=pp_params,\n",
    "    num_workers=num_workers,\n",
    "    isolation_widths=None,\n",
    "    aligned_names=f\"{len(fullscan_paths)}_beer_peak_picked.csv\",\n",
    "    force_peak_picking = False,\n",
    "    check_files = \"exact\"\n",
    ")\n",
    "\n",
    "exp.summarise(\n",
    "    num_workers=num_workers,\n",
    "    min_intensities=intensity_threshold,\n",
    "    rank_key = \"cumulative_intensity_proportion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9acf17-4787-4b31-95a7-3a9e3765f11c",
   "metadata": {},
   "source": [
    "Firstly, we can see that recomputing the full assignment (on the same original object) improved the result in this unexpected environment. Secondly, we can see that a persistent lengthening of scan times causes systemic failure for the pre-scheduled matching, but this can addressed with `TaskFilter`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee87543-6158-4966-929b-3b3d5d8cdb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
